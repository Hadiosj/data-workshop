{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Lab, Nancy 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning about different data science concepts (scraping, visualization, data manipulation, machine learning..), you will now work on your own, on a workshop similar to the one presented\n",
    "\n",
    "You should go through this notebook, and  fill in the code whenever you see `TODO:` written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by installing and importing the needed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add other packages you need to install here\n",
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "WAoZi6Mlg121"
   },
   "outputs": [],
   "source": [
    "# TODO: Add any additional imports you need\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OvKzXnCFM3_"
   },
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1c08_fkEkrE"
   },
   "source": [
    "We will once again be scraping data from the [understat.com](https://understat.com) website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "5GdbwW7Tg127"
   },
   "outputs": [],
   "source": [
    "# Create a URL based on your choice of league and season\n",
    "# TODO: Add your URL below\n",
    "url = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to see if your URL is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not url.startswith('https://understat.com/'):\n",
    "        print(\"❌ URL must start with 'https://understat.com/'\")\n",
    "    else:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✅ URL is valid: {url}\")\n",
    "        else:\n",
    "            print(f\"❌ URL is invalid: {url}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"❌ URL is invalid: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scrape the corresponding page just as seen in the workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXPittjCP4V6"
   },
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "scripts = soup.find_all('script')\n",
    "string_with_json_obj = ''\n",
    "for script in scripts:\n",
    "    if 'teamsData' in str(script):\n",
    "        string_with_json_obj = str(script).strip()\n",
    "ind_start = string_with_json_obj.index(\"('\")+2\n",
    "ind_end = string_with_json_obj.index(\"')\")\n",
    "json_data = string_with_json_obj[ind_start:ind_end]\n",
    "json_data = json_data.encode('utf8').decode('unicode_escape')\n",
    "data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame from the JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for team_id, team_data in data.items():\n",
    "    for game in team_data['history']:\n",
    "        row = {'team_name': team_data['title']}\n",
    "        row.update(game)\n",
    "        rows.append(row)\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Check the data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you'll create visualizations to explore the data you've scraped, in order to understand different relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert 'date' to datetime and sort by date\n",
    "df['date'] = \"YOUR CODE HERE\"\n",
    "df = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the 'date' and 'result' of the first 5 matches of a team of your choice\n",
    "team_name = \"YOUR CODE HERE\"\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: How many match was won at home, and how many away (accross all teams)? Can we deduce anything from this?\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Who won the league? With how many points? (i.e. which team has the most points at the end of the season)\n",
    "# TODO: Bonus: Can you display the table with the points of all teams sorted by points?\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you'll prepare the data in order to answer the following question:\n",
    "\n",
    "> Can we predict match results using advanced metrics like Expected Goals (xG)?\n",
    "\n",
    "\n",
    "Meaning that unlike the previous workshop, we'll prepare our data for a **classification model** this time, in order to predict match outcomes (Win, Loss, or Draw) based on various metrics like xG, xGA, and others.\n",
    "\n",
    "The general steps for preprocessing will be:\n",
    "1. Handle categorical features  \n",
    "2. Select relevant features\n",
    "3. Split into training and testing sets\n",
    "4. Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame for our classification task to avoid modifying the original\n",
    "df_class = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle categorical features\n",
    "# 1. Convert 'h_a' to numeric (1 for home, 0 for away)\n",
    "# 2. Convert 'result' to numeric (1 for win, 0 for draw, -1 for loss)\n",
    "df_class['h_a'] = \"YOUR CODE HERE\"\n",
    "df_class['result'] = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select features for your classification model\n",
    "# Think about which metrics might be most predictive of match outcomes (is the date important?)\n",
    "features = [\"YOUR\", \"CODE\", \"HERE\"]\n",
    "X = \"YOUR CODE HERE\"\n",
    "y = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into training (85%) and testing (15%) sets\n",
    "# 1. Use train_test_split from sklearn\n",
    "# 2. The test size should be 15% of the data\n",
    "# 3. Use stratify to ensure the same proportion of classes in both sets\n",
    "X_train, X_test, y_train, y_test = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scale your features using StandardScaler (make sure to fit the scaler on the training data only, but transform both)\n",
    "scaler = \"YOUR CODE HERE\"\n",
    "X_train_scaled = \"YOUR CODE HERE\"\n",
    "X_test_scaled = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now train and test a **Classifier** model (unlike the **regression** model previously used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your selected model on the training data\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions on the test set\n",
    "y_pred = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the accuracy score of your model\n",
    "accuracy = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate classification report to better understand the model's performance\n",
    "report  = \"YOUR CODE HERE\"\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a confusion matrix heatmap (using sns) to visualize the model's performance\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the feature_importances_ attribute of the classifier to analyse the importance of each feature in the model\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge: Predicting Over/Under Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bonus challenge, create a model to predict whether a match will have over or under a certain number of goals (e.g., over/under 2.5 goals). This is a common betting market in football.\n",
    "\n",
    "Steps:\n",
    "1. Create a new target variable for over/under 2.5 goals\n",
    "2. Preprocess the data as before\n",
    "3. Train a model and evaluate its performance\n",
    "4. Compare its accuracy to the previous match outcome prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for the over/under prediction task\n",
    "df_over_under = df.copy()\n",
    "\n",
    "# TODO: Create target variable (1 for over 2.5 goals, 0 for under 2.5 goals)\n",
    "# Your code here\n",
    "\n",
    "# TODO: Process features, split data, and train a classifier\n",
    "# Your code here\n",
    "\n",
    "# TODO: Evaluate model performance\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for your participation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
